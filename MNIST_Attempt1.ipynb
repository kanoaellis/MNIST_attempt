{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An attempt to create a model for the MNIST dataset using Tensorflow 2.0 beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 100\n",
    "baseline_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "baseline_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 10\n",
    "baseline_history = baseline_model.fit(x_train, y_train, epochs = epoch_size, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 10\n",
    "small_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "small_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "small_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_history = small_model.fit(x_train, y_train, epochs = epoch_size, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 1000\n",
    "large_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "large_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "large_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_history = large_model.fit(x_train, y_train, epochs = epoch_size, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function taken from: https://www.tensorflow.org/beta/tutorials/keras/overfit_and_underfit\n",
    "def plot_history(histories, key = 'sparse_categorical_crossentropy'):\n",
    "  plt.figure(figsize = (16, 10))\n",
    "\n",
    "  for name, history in histories:\n",
    "    val = plt.plot(history.epoch, history.history['val_' + key],\n",
    "                   '--', label = name.title() + ' Val')\n",
    "    plt.plot(history.epoch, history.history[key], color = val[0].get_color(),\n",
    "             label=name.title() + ' Train')\n",
    "\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel(key.replace('_', ' ').title())\n",
    "  plt.legend()\n",
    "\n",
    "  plt.xlim([0, max(history.epoch)])\n",
    "\n",
    "\n",
    "plot_history([('baseline', baseline_history),\n",
    "              ('small', small_history),\n",
    "              ('large', large_history)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 100\n",
    "l2_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, kernel_regularizer = tf.keras.regularizers.l2(0.001), activation = 'relu'),\n",
    "    #tf.keras.layers.Dense(hidden_layer_size, kernel_regularizer = tf.keras.regularizers.l2(0.001), activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "l2_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "l2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_history = l2_model.fit(x_train, y_train, epochs = epoch_size, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 100\n",
    "drop_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    #tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    #tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "drop_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "drop_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_history = drop_model.fit(x_train, y_train, epochs = epoch_size, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('baseline', baseline_history),\n",
    "              ('L2', l2_history),\n",
    "              ('dropout', drop_history)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 and Dropout model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 100\n",
    "l2d_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, kernel_regularizer = tf.keras.regularizers.l2(0.001), activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    #tf.keras.layers.Dense(hidden_layer_size, kernel_regularizer = tf.keras.regularizers.l2(0.001), activation = 'relu'),\n",
    "    #tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "l2d_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "l2d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2d_history = l2d_model.fit(x_train, y_train, epochs = epoch_size, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2d_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('baseline', baseline_history),\n",
    "              ('L2 and dropout', l2d_history)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 100\n",
    "deep_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "deep_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 10\n",
    "deep_history = deep_model.fit(x_train, y_train, epochs = epoch_size, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('baseline', baseline_history),\n",
    "              ('Deep', deep_history)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 200\n",
    "final_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "final_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy', 'sparse_categorical_crossentropy'])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_history = final_model.fit(x_train, y_train, epochs = 5, validation_data = (x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('baseline', baseline_history),\n",
    "              ('Final', final_history)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_TF2.0] *",
   "language": "python",
   "name": "conda-env-py3_TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
